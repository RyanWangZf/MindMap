# 使用思维导图在LLM中实现稳健且可解释的推理

像 GPT-3.5 这样的大型语言模型 （LLM） 已经展示了令人印象深刻的自然语言功能。然而，他们的推理过程仍然不透明，容易产生幻觉，且微调LLM成本极其昂贵。

最近提出的思维导图MindMap提出了一种推进思路，通过将知识图谱(KG)引入LLMs，使其能够理解KG输入并结合内部和外部知识进行推理。此外，还研究了如何提取LLMs的思维图，作为其推理和回答生成的依据。

Paper:

MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Larg Language Models

Link:

https://arxiv.org/pdf/2308.09729.pdf


![fig1](https://github.com/wyl-willing/MindMap/assets/63191675/9952e7fd-1274-44c4-9349-fb181400748e)


这项工作的目标是建立一个即插即用的提示方法来引出法学硕士的思维图推理能力。之所以称之为MindMap思维导图，因为它使法学硕士能够理解图形输入，以构建他们自己的思维导图，支持基于证据的生成。

我们的框架的概念性演示如下所示。具体来说，思维导图激发了llm的思维图，它
- (1)巩固了从KGs中检索到的事实和从llm中获得的隐性知识，
- (2)在输入KGs中发现新的模式，
- (3)通过思维导图产生最终输出。

我们在三个数据集上进行了实验，以说明MindMap在很大程度上优于一系列提示方法。这项工作强调了LLM如何学习与KG进行协同推理，将隐式和显式知识结合起来，以实现透明和可靠的推理。具体代码细节可以参考https://github.com/wyl-willing/MindMap.

![concept graph](https://github.com/wyl-willing/MindMap/assets/63191675/9221566a-570e-4b8c-9bba-b80e1741b2ad)


# 这项研究的贡献是什么？

这项研究的贡献在于探索了LLM在图输入上的推理能力，并强调了联合推理与内隐和外部显式知识的结合。

同时模型提出了一个值得研究的问题，针对一般性的任务（不需要额外检索信息）时，像GPT-3.5这样的LLM模型表现得更好，而检索方法表现得很差。这表明检索方法在一定程度上忽略了LLM所学的知识。因此，在设计通用型LLM时，有效地将LLM本身的知识与KG知识融合协同推理是非常有必要的。

# 总结

思维导图提供了一个可解释的通道，通过提示LLM对结构化知识图谱知识进行推理，使用其隐含知识和聚合的知识图谱证据来跟踪LLM的推理。这可视化了询问模型的思维过程的合理性和事实基础。这种透明的推理图能够在结合外部和内部知识的同时检测和避免潜在的幻觉。

通过这种方式，可以将结构化知识、紧急推理和神经语言理解的优势结合起来，以获得更强大和可解释的智能！

